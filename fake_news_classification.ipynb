{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ababbf-8cef-4b15-b26d-9f13374a19fb",
   "metadata": {},
   "source": [
    "# Fake News Classification with Spacy Word Vectors\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "This project aims to build a machine learning model to accurately classify news articles as either **Real** or **Fake**. This is a classic example of a binary text classification problem in Natural Language Processing (NLP).\n",
    "\n",
    "Our approach will be to convert the text of each news article into a meaningful numerical representation using **spaCy's word vectors**. These vectors capture the semantic meaning of the text. We will then train and compare several machine learning models to see which performs best at this classification task.\n",
    "\n",
    "The workflow is as follows:\n",
    "1.  Load the dataset and perform a quick exploratory analysis.\n",
    "2.  Preprocess the text and generate sentence embeddings using spaCy.\n",
    "3.  Train and evaluate four different classification models:\n",
    "    - K-Nearest Neighbors (KNN)\n",
    "    - Logistic Regression\n",
    "    - Support Vector Machine (SVM)\n",
    "    - Gaussian Naive Bayes (the correct Naive Bayes variant for this data)\n",
    "4.  Compare the results and draw a conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f787aad5-6a38-4c8c-bc5c-867dfe7bc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/hasancan/Downloads/fake_news.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f9219-4254-41be-875b-84a9a3933fe5",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration\n",
    "\n",
    "First, let's examine the structure of our dataset and the distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dcdb470-a994-445e-8195-2a4da18af25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
       "1  U.S. conservative leader optimistic of common ...  Real\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "print(\"Dataset preview:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93449c93-0f36-4a79-911f-69176d252d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "Fake    5000\n",
       "Real    4900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of 'Fake' vs. 'Real' news\n",
    "print(\"\\nClass distribution:\")\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334aeff6-c66d-4493-9f6d-a815c557bd46",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "The dataset is well-balanced, with an almost equal number of \"Fake\" and \"Real\" news articles. This is great, as it means we don't need to perform techniques like over-sampling or under-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9014de-ebd1-40b2-8831-2a0b7909da0f",
   "metadata": {},
   "source": [
    "## 3. Preprocessing and Feature Engineering\n",
    "\n",
    "### 3.1. Label Encoding\n",
    "Machine learning models require numerical inputs, so we'll convert our text labels ('Fake', 'Real') into numerical labels (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28c9f7ca-16ff-40d2-acc7-eb51ce656e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label  label_num\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake          0\n",
       "1  U.S. conservative leader optimistic of common ...  Real          1\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real          1\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake          0\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real          1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert text labels to numerical labels\n",
    "df['label_num'] = df['label'].map({'Fake': 0, 'Real': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c387853-9447-422f-bc42-c7d9b23fe55e",
   "metadata": {},
   "source": [
    "### 3.2. Text to Vector Conversion\n",
    "We will use spaCy to convert each news article's text into a dense vector, also known as an embedding. We'll use the `en_core_web_sm` model. For each document, spaCy calculates the average of all the word vectors, resulting in a single vector that represents the entire text's meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc374a-5e27-44a2-8155-cf518622bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the small English spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Create a new column 'vector' by applying the nlp pipeline to our 'Text' column\n",
    "# The .vector attribute gives the average vector for the entire document\n",
    "df['vector'] = df['Text'].apply(lambda text: nlp(text).vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8129cb9-c6e1-4e10-80bb-29782b78d193",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation\n",
    "\n",
    "With our data prepared, we can now split it into training and testing sets and train our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d53818-00c9-480a-897f-48923c5f2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.vector.values,      # Features (our vectors)\n",
    "    df.label_num,          # Target\n",
    "    test_size=0.2,         # 20% of data will be for testing\n",
    "    random_state=6,        # For reproducibility\n",
    "    stratify=df.label_num  # Ensure balanced classes in train/test sets\n",
    ")\n",
    "\n",
    "# Reshape the data for scikit-learn\n",
    "# np.stack converts the series of arrays into a single 2D numpy array\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f99d0b-7d24-4a51-8533-d7a2439e933c",
   "metadata": {},
   "source": [
    "Now, let's train our four models and evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4bab07-0515-45fc-9d30-b7c525deaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 1: K-Nearest Neighbors (KNN) ---\n",
    "# KNN is a distance-based classifier that works well with vector embeddings.\n",
    "print(\"--- Training K-Nearest Neighbors ---\")\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "model_knn.fit(X_train_2d, y_train)\n",
    "y_pred_knn = model_knn.predict(X_test_2d)\n",
    "print(\"\\nClassification Report (KNN):\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4436187-dc4b-4f0d-b870-edcd0bd19d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 2: Logistic Regression ---\n",
    "# A strong and reliable baseline for binary classification.\n",
    "print(\"\\n--- Training Logistic Regression ---\")\n",
    "model_logreg = LogisticRegression(max_iter=1000)\n",
    "model_logreg.fit(X_train_2d, y_train)\n",
    "y_pred_logreg = model_logreg.predict(X_test_2d)\n",
    "print(\"\\nClassification Report (Logistic Regression):\")\n",
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a145db9f-e3ef-42a6-abe3-8eb60bc070e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 3: Support Vector Machine (SVM) ---\n",
    "# SVMs are excellent for high-dimensional data like ours.\n",
    "print(\"\\n--- Training Support Vector Machine ---\")\n",
    "model_svc = SVC(kernel='linear')\n",
    "model_svc.fit(X_train_2d, y_train)\n",
    "y_pred_svc = model_svc.predict(X_test_2d)\n",
    "print(\"\\nClassification Report (Support Vector Machine):\")\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc6491-4ea3-4b47-abf9-dfd460bdb641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 4: Gaussian Naive Bayes ---\n",
    "# This is the correct Naive Bayes variant for continuous features like word vectors.\n",
    "# MultinomialNB is for word counts, not dense vectors.\n",
    "print(\"\\n--- Training Gaussian Naive Bayes ---\")\n",
    "model_gnb = GaussianNB()\n",
    "model_gnb.fit(X_train_2d, y_train)\n",
    "y_pred_gnb = model_gnb.predict(X_test_2d)\n",
    "print(\"\\nClassification Report (Gaussian Naive Bayes):\")\n",
    "print(classification_report(y_test, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744be7d7-d46d-40a0-8bdf-9e841f1e96e4",
   "metadata": {},
   "source": [
    "## 5. Conclusion and Summary\n",
    "\n",
    "Let's summarize the performance of all four models to determine the best one for our fake news classification task.\n",
    "\n",
    "| Model | Accuracy |\n",
    "| :--- | :---: |\n",
    "| **K-Nearest Neighbors** | **98%** |\n",
    "| **Logistic Regression** | **95%** |\n",
    "| **Support Vector Machine**| **95%** |\n",
    "| **Gaussian Naive Bayes** | **94%** |\n",
    "\n",
    "### Analysis\n",
    "All models performed exceptionally well, with accuracies above 94%. However, **K-Nearest Neighbors (KNN) was the clear winner with an outstanding 98% accuracy**.\n",
    "\n",
    "The high performance across the board demonstrates that spaCy's pre-trained word vectors are highly effective at capturing the semantic differences between real and fake news articles. KNN's success suggests that in the vector space, articles of the same class are very closely clustered, making a distance-based algorithm like KNN a natural fit.\n",
    "\n",
    "### Future Work\n",
    "- **Hyperparameter Tuning:** We could use `GridSearchCV` to find the optimal `n_neighbors` for KNN or the `C` parameter for SVM to potentially improve scores further.\n",
    "- **Advanced Embeddings:** Experiment with larger spaCy models (`en_core_web_lg`) or other embedding techniques like BERT for even more nuanced text representations.\n",
    "- **Deep Learning:** A simple neural network or an LSTM could be trained on these vectors to see if it can capture more complex patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
